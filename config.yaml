# Moltbook Human-Like Detection Pipeline Configuration
# Edit these values or pass --config overrides from the CLI.

random_seed: 42

# Sample mode: set to true for fast iteration (uses sample_size posts)
sample_mode: false
sample_size: 1000

# Column names in the Moltbook posts dataset
# The raw "post" column is a nested dict; the pipeline flattens it during validation.
# After flattening, the text lives in "content" and the ID in "id".
id_column: "id"
text_column: "content"
category_column: "topic_label"
toxicity_column: "toxic_level"
submolt_column: "submolt_name"

# Perplexity language model
# Primary: Llama 3.2 1B (gated â€” requires HF token and model approval)
# Fallback: GPT-2 medium (no auth required)
perplexity_model: "meta-llama/Llama-3.2-1B"
perplexity_fallback_model: "gpt2-medium"

# Sentence-transformer for embedding-based outlier metrics
embedding_model: "all-MiniLM-L6-v2"

# Outlier detection
outlier_contamination: 0.05
outlier_thresholds:
  - 0.90
  - 0.95
  - 0.99

# Audit sampling
audit_sample_size: 100

# Text quality bounds
min_text_length: 10
max_text_length: 50000
